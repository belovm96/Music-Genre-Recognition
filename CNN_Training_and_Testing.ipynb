{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    exp_name = 'CNN_For_Spectrogram'\n",
    "    #make a directory for the experiment\n",
    "    if not os.path.exists(exp_name):\n",
    "        os.makedirs(exp_name)\n",
    "    parser = argparse.ArgumentParser(description=exp_name)\n",
    "\n",
    "    #add hyperparameters to the parser\n",
    "    parser.add_argument('--batch-size', type=int, default=10,\n",
    "                    help='input batch size for training (default: 10)')\n",
    "    parser.add_argument('--epochs', type=int, default=50,\n",
    "                    help='number of epochs to train (default: 50)')\n",
    "    parser.add_argument('--freq-dim', type=int, default=432,\n",
    "                    help='row dimension of the feature')\n",
    "    parser.add_argument('--cuda', action='store_true', default=True,\n",
    "                    help='enables CUDA training (default: True)')  # when you have a GPU\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                    help='learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--model-save', type=str,  default='best_model_CNN_Spectrogram.pt',\n",
    "                    help='path to save the best model')\n",
    "    parser.add_argument('--tr-data', type=str,  default='training_specs_GTZAN_more.hdf5',\n",
    "                    help='path to training dataset')\n",
    "    parser.add_argument('--val-data', type=str,  default='validation_specs_GTZAN_more.hdf5',\n",
    "                    help='path to training dataset')\n",
    "    parser.add_argument('--test-data', type=str,  default='testing_specs_GTZAN_more.hdf5',\n",
    "                    help='path to training dataset')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    args.cuda = args.cuda and torch.cuda.is_available()\n",
    "\n",
    "    if args.cuda:\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "    else:\n",
    "        kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class CNN_Tempogram(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN_Tempogram, self).__init__()\n",
    "        \n",
    "            self.kernel = 5\n",
    "            self.channel = 16\n",
    "            self.output = 10\n",
    "            \n",
    "            self.cnn1 = nn.Conv2d(in_channels=1, out_channels=self.channel, kernel_size=self.kernel, stride=1, padding=(self.kernel-1)//2)\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "            \n",
    "            self.cnn2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=5, stride=1, padding=(self.kernel-1)//2)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "            \n",
    "            self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=(3-1)//2)\n",
    "            self.relu3 = nn.ReLU()\n",
    "            self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "            self.fc = nn.Linear(62208, self.output)\n",
    "        \n",
    "        def forward(self, input):\n",
    "            \n",
    "            input = input.unsqueeze(1)\n",
    "            \n",
    "            out = self.cnn1(input)\n",
    "            out = self.relu1(out)\n",
    "            out = self.maxpool1(out)\n",
    "        \n",
    "            \n",
    "            out = self.cnn2(out)\n",
    "            out = self.relu2(out)\n",
    "            out = self.maxpool2(out)\n",
    "            \n",
    "            out = self.cnn3(out)\n",
    "            out = self.relu3(out)\n",
    "            out = self.maxpool3(out)\n",
    "           \n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.fc(out)\n",
    "        \n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Tempogram(\n",
      "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=62208, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    model_CNN = CNN_Tempogram()\n",
    "    print(model_CNN)\n",
    "\n",
    "    if args.cuda:\n",
    "        model_CNN = model_CNN.cuda()\n",
    "\n",
    "    #define the optimizer\n",
    "    optimizer = optim.Adam(model_CNN.parameters(), lr=args.lr)\n",
    "    scheduler  = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class dataset_pipeline(Dataset):\n",
    "        def __init__(self, path):\n",
    "            super(dataset_pipeline, self).__init__()\n",
    "            \n",
    "            self.h5pyLoader = h5py.File(path, 'r')\n",
    "            \n",
    "            self.labels = self.h5pyLoader['labels_spec_int']\n",
    "            \n",
    "            self.temp = self.h5pyLoader['spectrogram']\n",
    "        \n",
    "            self._len = self.temp.shape[0]  # number of utterances\n",
    "            \n",
    "        def __getitem__(self, index):\n",
    "            \n",
    "            temp_item = torch.from_numpy(self.temp[index].astype(np.float32))\n",
    "            \n",
    "            label_item = torch.from_numpy(np.array(self.labels[index]).astype(np.float32))\n",
    "            label_item = torch.tensor(label_item, dtype = torch.long)\n",
    "            \n",
    "            return (temp_item, label_item)\n",
    "    \n",
    "        def __len__(self):\n",
    "            return self._len\n",
    "        \n",
    "    \n",
    "    #define data loaders\n",
    "    train_loader = DataLoader(dataset_pipeline(args.tr_data), \n",
    "                          batch_size=args.batch_size, \n",
    "                          shuffle=True, \n",
    "                          **kwargs)\n",
    "\n",
    "    validation_loader = DataLoader(dataset_pipeline(args.val_data), \n",
    "                               batch_size=args.batch_size, \n",
    "                               shuffle=False, \n",
    "                               **kwargs)\n",
    "    \n",
    "    \n",
    "    test_loader = DataLoader(dataset_pipeline(args.test_data), \n",
    "                               batch_size=args.batch_size, \n",
    "                               shuffle=False, \n",
    "                           **kwargs)\n",
    "    \n",
    "    args.dataset_len = len(train_loader)\n",
    "    args.log_step = args.dataset_len // 4\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(model, epoch, versatile=True):\n",
    "        #set the model to training mode\n",
    "        model = model.train() \n",
    "        train_loss = 0\n",
    "        accuracy_train = 0\n",
    "    \n",
    "        #load batch data\n",
    "        for batch_idx, (data,labels) in enumerate(train_loader):\n",
    "        \n",
    "            batch_label = labels\n",
    "            batch_temp = data\n",
    "            \n",
    "            if args.cuda:\n",
    "                batch_temp = batch_temp.cuda()\n",
    "        \n",
    "            #clean up the gradients in the optimizer\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            temp_output = model(batch_temp)\n",
    "        \n",
    "            #CrossEntropy as loss function\n",
    "            loss = criterion(temp_output, batch_label)\n",
    "            \n",
    "            _, predicted = torch.max(temp_output.data, 1)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0    \n",
    "            #total number of labels\n",
    "            total += batch_label.size(0)\n",
    "               \n",
    "            correct += (predicted == batch_label).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "        \n",
    "            #automatically calculate the backward pass\n",
    "            loss.backward()\n",
    "            #perform the actual back-propagation\n",
    "            optimizer.step()\n",
    "            \n",
    "            accuracy_train += accuracy\n",
    "            \n",
    "            train_loss += loss.data.item()\n",
    "        \n",
    "            #print the training progress \n",
    "            if versatile:\n",
    "                if (batch_idx+1) % args.log_step == 0:\n",
    "                \n",
    "                    print('| epoch {:3d} | {:5d}/{:5d} batches | Loss {:5.4f} | Accuracy {} |'.format(\n",
    "                    epoch, batch_idx+1, len(train_loader),\n",
    "                    train_loss / (batch_idx+1), accuracy_train/ (batch_idx+1)\n",
    "                    ))\n",
    "    \n",
    "        train_loss /= (batch_idx+1)\n",
    "        accuracy_train /= (batch_idx+1)\n",
    "        print('-' * 99)\n",
    "        print('    | end of training epoch {:3d} | Loss {:5.4f} | Accuracy {} |'.format(\n",
    "            epoch, train_loss, accuracy_train))\n",
    "    \n",
    "        return train_loss, accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def validate(model, epoch):\n",
    "        #set the model to evaluation mode, this is important if you have BatchNorm in your model!\n",
    "        model = model.eval()\n",
    "        validation_loss = 0.\n",
    "        accuracy_valid = 0\n",
    "        #load batch data\n",
    "        for batch_idx, (data,labels) in enumerate(validation_loader):\n",
    "            \n",
    "            batch_temp = data\n",
    "            batch_label = labels\n",
    "        \n",
    "            if args.cuda:\n",
    "                batch_temp = batch_temp.cuda()\n",
    "        \n",
    "            #call torch.no_grad() to only calculate the forward pass, save time and memory\n",
    "            with torch.no_grad():\n",
    "        \n",
    "                temp_output = model(batch_temp)\n",
    "               \n",
    "            \n",
    "                loss = criterion(temp_output, batch_label)\n",
    "        \n",
    "                validation_loss += loss.data.item()\n",
    "                \n",
    "                _, predicted = torch.max(temp_output.data, 1)\n",
    "               \n",
    "                correct = 0\n",
    "                total = 0    \n",
    "                \n",
    "                total += batch_label.size(0)\n",
    "                \n",
    "                correct += (predicted == batch_label).sum()\n",
    "                \n",
    "                accuracy = 100 * correct / total\n",
    "                \n",
    "                accuracy_valid += accuracy\n",
    "        \n",
    "        validation_loss /= (batch_idx+1)\n",
    "        accuracy_valid /= (batch_idx+1)\n",
    "        print('    | end of validation epoch {:3d} | Loss {:5.4f} | Accuracy {} |'.format(\n",
    "            epoch, validation_loss, accuracy_valid))\n",
    "        print('-' * 99)\n",
    "    \n",
    "        return validation_loss, accuracy_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "    accuracy_tr = []\n",
    "    accuracy_vl = []\n",
    "    decay_cnt = 0\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        if args.cuda:\n",
    "            model_CNN.cuda()\n",
    "        ls_tr, acc_tr = train(model_CNN, epoch)\n",
    "        ls_val, acc_val = validate(model_CNN, epoch)\n",
    "        training_loss.append(ls_tr)\n",
    "        validation_loss.append(ls_val)\n",
    "        accuracy_tr.append(acc_tr)\n",
    "        accuracy_vl.append(acc_val)\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        if accuracy_tr[-1] == np.max(accuracy_tr):\n",
    "            print('      Best training model found.')\n",
    "        if accuracy_vl[-1] == np.max(accuracy_vl):\n",
    "            #save current best model\n",
    "            with open(args.model_save, 'wb') as f:\n",
    "                torch.save(model_CNN.cpu().state_dict(), f)\n",
    "                print('      Best validation model found and saved.')\n",
    "    \n",
    "        print('-' * 99)\n",
    "        decay_cnt += 1\n",
    "   \n",
    "        #decay when no best training model is found for 3 consecutive epochs\n",
    "        if np.min(training_loss) not in training_loss[-3:] and decay_cnt >= 3:\n",
    "            scheduler.step()\n",
    "            decay_cnt = 0\n",
    "            print('      Learning rate decreased.')\n",
    "            print('-' * 99)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
